import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris

def sigmoid(z):  # modified for logistic regression
    return 1 / (1 + np.exp(-z))  # modified for logistic regression

def gradient_descent(X, y, learning_rate=0.01, epochs=1000):
    m, n = X.shape
    W = np.zeros(n + 1)
    X_b = np.c_[np.ones((m, 1)), X]

    for epoch in range(epochs):
        z = X_b.dot(W)                          # modified for logistic regression
        y_pred = sigmoid(z)                     # modified for logistic regression
        error = y_pred - y
        gradient = (1/m) * X_b.T.dot(error)
        W -= learning_rate * gradient

        if epoch % 100 == 0:
            loss = - (1/m) * np.sum(y * np.log(y_pred + 1e-9) + (1 - y) * np.log(1 - y_pred + 1e-9))  # modified for logistic regression
            print(f"Epoch {epoch}, Loss: {loss}, Gradient: {gradient}")

    return W

if __name__ == "__main__":
    # Load iris dataset (two classes only)
    iris = load_iris()
    X = iris.data[:100, :2]  # first 2 features and 2 classes
    y = iris.target[:100]
    
    # Convert labels to binary (0 and 1)
    y = (y == 1).astype(int)  # modified for logistic regression

    # Train model
    weights = gradient_descent(X, y, learning_rate=0.1, epochs=1000)

    print("Intercept (w0):", weights[0])
    print("Weights:", weights[1:])

    # Plot decision boundary
    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr', label='Data Points')

    x_min, x_max = X[:, 0].min(), X[:, 0].max()
    x_values = np.linspace(x_min, x_max, 100)
    y_values = -(weights[0] + weights[1] * x_values) / weights[2]
    plt.plot(x_values, y_values, color='black', label='Decision Boundary')

    plt.xlabel(iris.feature_names[0])
    plt.ylabel(iris.feature_names[1])
    plt.title('Logistic Regression (Iris)')
    plt.legend()
    plt.show()
